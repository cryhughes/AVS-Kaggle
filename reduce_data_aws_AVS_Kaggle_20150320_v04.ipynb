{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import\n",
    "import os\n",
    "\n",
    "#for operations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#for AWS connection\n",
    "from boto.s3.connection import S3Connection\n",
    "from IPython.parallel import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get creds for aws\n",
    "credentials = pd.read_csv('/home/centos/certificates/credentials.csv')\n",
    "aws_id = credentials['Access Key Id'][0]\n",
    "aws_key = credentials['Secret Access Key'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#connect to S3 for data\n",
    "s3conn = S3Connection( aws_id , aws_key )\n",
    "bucket = s3conn.get_bucket('avs-kaggle-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load offers data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers_keys = bucket.get_all_keys(prefix='offers')\n",
    "len( offers_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "offers_keys[0].get_contents_to_filename('offers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offer</th>\n",
       "      <th>category</th>\n",
       "      <th>quantity</th>\n",
       "      <th>company</th>\n",
       "      <th>offervalue</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1190530</td>\n",
       "      <td> 9115</td>\n",
       "      <td> 1</td>\n",
       "      <td> 108500080</td>\n",
       "      <td> 5.00</td>\n",
       "      <td> 93904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 1194044</td>\n",
       "      <td> 9909</td>\n",
       "      <td> 1</td>\n",
       "      <td> 107127979</td>\n",
       "      <td> 1.00</td>\n",
       "      <td>  6732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 1197502</td>\n",
       "      <td> 3203</td>\n",
       "      <td> 1</td>\n",
       "      <td> 106414464</td>\n",
       "      <td> 0.75</td>\n",
       "      <td> 13474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     offer  category  quantity    company  offervalue  brand\n",
       "0  1190530      9115         1  108500080        5.00  93904\n",
       "1  1194044      9909         1  107127979        1.00   6732\n",
       "2  1197502      3203         1  106414464        0.75  13474"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers_df = pd.read_csv('offers.csv')\n",
    "print offers_df.shape\n",
    "offers_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load test_hist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hist_keys = bucket.get_all_keys(prefix='trainHistory')\n",
    "len( train_hist_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_hist_keys[0].get_contents_to_filename('trainHistory.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160057, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>chain</th>\n",
       "      <th>offer</th>\n",
       "      <th>market</th>\n",
       "      <th>repeattrips</th>\n",
       "      <th>repeater</th>\n",
       "      <th>offerdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>    86246</td>\n",
       "      <td> 205</td>\n",
       "      <td> 1208251</td>\n",
       "      <td> 34</td>\n",
       "      <td>  5</td>\n",
       "      <td> t</td>\n",
       "      <td> 2013-04-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>    86252</td>\n",
       "      <td> 205</td>\n",
       "      <td> 1197502</td>\n",
       "      <td> 34</td>\n",
       "      <td> 16</td>\n",
       "      <td> t</td>\n",
       "      <td> 2013-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 12682470</td>\n",
       "      <td>  18</td>\n",
       "      <td> 1197502</td>\n",
       "      <td> 11</td>\n",
       "      <td>  0</td>\n",
       "      <td> f</td>\n",
       "      <td> 2013-03-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  chain    offer  market  repeattrips repeater   offerdate\n",
       "0     86246    205  1208251      34            5        t  2013-04-24\n",
       "1     86252    205  1197502      34           16        t  2013-03-27\n",
       "2  12682470     18  1197502      11            0        f  2013-03-28"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hist_df = pd.read_csv('trainHistory.csv')\n",
    "print train_hist_df.shape\n",
    "train_hist_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### merge offers and test_hist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160057, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>chain</th>\n",
       "      <th>offer</th>\n",
       "      <th>market</th>\n",
       "      <th>repeattrips</th>\n",
       "      <th>repeater</th>\n",
       "      <th>offerdate</th>\n",
       "      <th>category</th>\n",
       "      <th>quantity</th>\n",
       "      <th>company</th>\n",
       "      <th>offervalue</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>    86246</td>\n",
       "      <td> 205</td>\n",
       "      <td> 1208251</td>\n",
       "      <td> 34</td>\n",
       "      <td> 5</td>\n",
       "      <td> t</td>\n",
       "      <td> 2013-04-24</td>\n",
       "      <td> 2202</td>\n",
       "      <td> 1</td>\n",
       "      <td> 104460040</td>\n",
       "      <td> 2</td>\n",
       "      <td> 3718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 15753725</td>\n",
       "      <td>  17</td>\n",
       "      <td> 1208251</td>\n",
       "      <td>  4</td>\n",
       "      <td> 0</td>\n",
       "      <td> f</td>\n",
       "      <td> 2013-04-24</td>\n",
       "      <td> 2202</td>\n",
       "      <td> 1</td>\n",
       "      <td> 104460040</td>\n",
       "      <td> 2</td>\n",
       "      <td> 3718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 16535563</td>\n",
       "      <td>   4</td>\n",
       "      <td> 1208251</td>\n",
       "      <td>  1</td>\n",
       "      <td> 7</td>\n",
       "      <td> t</td>\n",
       "      <td> 2013-04-27</td>\n",
       "      <td> 2202</td>\n",
       "      <td> 1</td>\n",
       "      <td> 104460040</td>\n",
       "      <td> 2</td>\n",
       "      <td> 3718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 18259179</td>\n",
       "      <td>   3</td>\n",
       "      <td> 1208251</td>\n",
       "      <td>  2</td>\n",
       "      <td> 0</td>\n",
       "      <td> f</td>\n",
       "      <td> 2013-04-24</td>\n",
       "      <td> 2202</td>\n",
       "      <td> 1</td>\n",
       "      <td> 104460040</td>\n",
       "      <td> 2</td>\n",
       "      <td> 3718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 21024070</td>\n",
       "      <td>  15</td>\n",
       "      <td> 1208251</td>\n",
       "      <td>  9</td>\n",
       "      <td> 1</td>\n",
       "      <td> t</td>\n",
       "      <td> 2013-04-23</td>\n",
       "      <td> 2202</td>\n",
       "      <td> 1</td>\n",
       "      <td> 104460040</td>\n",
       "      <td> 2</td>\n",
       "      <td> 3718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  chain    offer  market  repeattrips repeater   offerdate  \\\n",
       "0     86246    205  1208251      34            5        t  2013-04-24   \n",
       "1  15753725     17  1208251       4            0        f  2013-04-24   \n",
       "2  16535563      4  1208251       1            7        t  2013-04-27   \n",
       "3  18259179      3  1208251       2            0        f  2013-04-24   \n",
       "4  21024070     15  1208251       9            1        t  2013-04-23   \n",
       "\n",
       "   category  quantity    company  offervalue  brand  \n",
       "0      2202         1  104460040           2   3718  \n",
       "1      2202         1  104460040           2   3718  \n",
       "2      2202         1  104460040           2   3718  \n",
       "3      2202         1  104460040           2   3718  \n",
       "4      2202         1  104460040           2   3718  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hist_offers_df = pd.merge( train_hist_df, offers_df, how='inner')\n",
    "\n",
    "print train_hist_offers_df.shape\n",
    "train_hist_offers_df.head(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#test write to csv (to project folder, then move to S3) \n",
    "train_hist_offers_df.to_csv('train_hist_offers_df.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%bash\n",
    "ls\n",
    "#train_test_offers_df.csv appears is listed ==> this works\n",
    "#next steps... how to push to AWS S3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%%bash\n",
    "#pwd\n",
    "scp -i /home/centos/certificates/mycert.pem /home/centos/projects/AVS-Kaggle/train_hist_offers_df.csv ec2-user@ec2-54-152-208-70.compute-1.amazonaws.com \n",
    "#this does not work ... note: will need to chg EC2 address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### import *relevant* transaction data in chunk_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Key: avs-kaggle-data,transactions-sample.csv>, <Key: avs-kaggle-data,transactions.csv.gz>, <Key: avs-kaggle-data,transactions.gz>]\n"
     ]
    }
   ],
   "source": [
    "trans_keys = bucket.get_all_keys(prefix='trans')\n",
    "len( trans_keys)\n",
    "print trans_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trans_keys[0].get_contents_to_filename('transactions.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'chain', 'dept', 'category', 'company', 'brand', 'date', 'productsize', 'productmeasure', 'purchasequantity', 'purchaseamount']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>chain</th>\n",
       "      <th>dept</th>\n",
       "      <th>category</th>\n",
       "      <th>company</th>\n",
       "      <th>brand</th>\n",
       "      <th>date</th>\n",
       "      <th>productsize</th>\n",
       "      <th>productmeasure</th>\n",
       "      <th>purchasequantity</th>\n",
       "      <th>purchaseamount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 86246</td>\n",
       "      <td> 205</td>\n",
       "      <td> 7</td>\n",
       "      <td> 707</td>\n",
       "      <td> 1078778070</td>\n",
       "      <td> 12564</td>\n",
       "      <td> 2012-03-02</td>\n",
       "      <td> 12</td>\n",
       "      <td> OZ</td>\n",
       "      <td> 1</td>\n",
       "      <td> 7.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  chain  dept  category     company  brand        date  productsize  \\\n",
       "0  86246    205     7       707  1078778070  12564  2012-03-02           12   \n",
       "\n",
       "  productmeasure  purchasequantity  purchaseamount  \n",
       "0             OZ                 1            7.59  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test w/o 'compression' kwarg ==> works\n",
    "col_df = pd.read_csv( 'transactions.csv.gz', \n",
    "                     engine='python', \n",
    "                     #compression='gzip',\n",
    "                     nrows=1) \n",
    "\n",
    "col_headers = list( col_df.columns)\n",
    "print col_headers\n",
    "\n",
    "col_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n"
     ]
    }
   ],
   "source": [
    "#define variables\n",
    "n=0 #test variable\n",
    "chunk_rows = 1000000\n",
    "rows_hist_train = 5000000 #test\n",
    "#rows_hist_train = 349655790 #actual figure, from bash cmd\n",
    "\n",
    "#iterate through transactions\n",
    "for skip_rows in range( 0, rows_hist_train, chunk_rows):\n",
    "    print skip_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip_rows:       0, chunk_rows: 1000000\n",
      "n: 0\n",
      "skip_rows: 1000000, chunk_rows: 1000000\n",
      "n: 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-a2350ccaa57a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m#read\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mtemp_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'transactions.csv.gz'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mskip_rows\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mchunk_rows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m                           \u001b[1;31m#header='col_headers',\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                           \u001b[1;31m#compression= 'gzip', #define for local, NOT for EC2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/centos/miniconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[0;32m    463\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/centos/miniconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/centos/miniconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/centos/miniconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    695\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/centos/miniconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:4797)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "#create empty df to append to\n",
    "train_df = pd.DataFrame()\n",
    "\n",
    "#get headers\n",
    "col_df = pd.read_csv( 'transactions.csv.gz', \n",
    "                     #compression='gzip', #define for local, NOT for EC2\n",
    "                     engine='python',\n",
    "                     nrows=1)\n",
    "col_headers = list( col_df.columns)\n",
    "#print col_headers\n",
    "\n",
    "#define variables\n",
    "n=0 #test variable\n",
    "chunk_rows = 1000000\n",
    "rows_hist_train = 5000000 #test\n",
    "#rows_hist_train = 349655790 #actual figure, from bash cmd\n",
    "\n",
    "#iterate through transactions\n",
    "for skip_rows in range( 0, rows_hist_train, chunk_rows):\n",
    "    \n",
    "    #test function inputs\n",
    "    print(\"skip_rows: %7d, chunk_rows: %7d\" %(skip_rows, chunk_rows)) \n",
    "    print (\"n: %1d\" %n)\n",
    "    \n",
    "    #read\n",
    "    temp_df = pd.read_csv('transactions.csv.gz', skiprows= skip_rows,nrows= chunk_rows) \n",
    "                          #header='col_headers',\n",
    "                          #compression= 'gzip', #define for local, NOT for EC2\n",
    "                          #compression='bz2', #ramesh suggestion\n",
    "                          #engine='python')\n",
    "                          #skiprows= skip_rows)\n",
    "    n = n+1 #increment for test\n",
    "    \n",
    "    #merge with train_hist_offers to pull ONLY relevant data, then append\n",
    "    temp_df.columns = col_headers\n",
    "    temp_df_2 = pd.merge( temp_df, train_hist_offers_df, how='inner')\n",
    "    train_df = train_df.append( temp_df_2)\n",
    "\n",
    "#write to csv\n",
    "train_df.to_csv('train_df_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
